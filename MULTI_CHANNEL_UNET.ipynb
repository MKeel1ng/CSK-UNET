{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"MULTI_CHANNEL_UNET.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm","mount_file_id":"1q4vHdH7wxVOaOymbjeHHslwXA0u47R62","authorship_tag":"ABX9TyPbM0MtnlWsZ4F4iTn/Islh"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"PSif1eKvJSCE","colab_type":"text"},"source":["**Connect to drive**"]},{"cell_type":"code","metadata":{"id":"1J_TfUQd78fR","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RU1VOFg2Jl0x","colab_type":"text"},"source":["**PART 1: SET UP THE FOLDERS** "]},{"cell_type":"code","metadata":{"id":"SOu3klhyJvjh","colab_type":"code","colab":{}},"source":["import os\n","import random\n","import re\n","from PIL import Image\n","\n","DATA_PATH = '/content/drive/My Drive/ThesisDL/IOUsemSeg'\n","MASK_PATH='/content/drive/My Drive/ThesisDL/IOUsemSeg/Nuc_Masks'\n","FRAME_PATH = '/content/drive/My Drive/ThesisDL/IOUsemSeg/Regression_Composites'\n","\n","\n","\n","# Create folders to hold images and masks\n","\n","folders = ['train_frames', 'train_masks', 'val_frames', 'val_masks', 'test_frames', 'test_masks']\n","\n","\n","for folder in folders:\n","  os.makedirs(DATA_PATH + '/' + folder)\n","  \n","  \n","# Get all frames and masks, sort them, shuffle them to generate data sets.\n","\n","\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TmMMNimWP5y6","colab_type":"code","colab":{}},"source":["all_frames = os.listdir(FRAME_PATH)\n","all_masks = os.listdir(MASK_PATH)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Iius8_IZN3rp","colab_type":"code","colab":{}},"source":["all_frames.sort(key=lambda var:[int(x) if x.isdigit() else x \n","                                for x in re.findall(r'[^0-9]|[0-9]+', var)])\n","all_masks.sort(key=lambda var:[int(x) if x.isdigit() else x \n","                               for x in re.findall(r'[^0-9]|[0-9]+', var)])\n","index=range(len(all_frames))\n","index2=[i for i in index]\n","\n","random.seed(230)\n","random.shuffle(index2)\n","\n","\n","\n","train_split = int(0.7*len(index2))\n","val_split = int(0.9 * len(index2))\n","\n","train_idx = index2[:train_split]\n","val_idx = index2[train_split:val_split]\n","test_idx = index2[val_split:]\n","\n","train_frames=[]\n","train_masks=[]\n","val_frames=[]\n","val_masks=[]\n","test_frames=[]\n","test_masks=[]\n","\n","for idx in train_idx:\n","  #print(idx)\n","  train_frames.append(all_frames[idx])\n","  train_masks.append(all_masks[idx])\n","\n","for idx in val_idx:\n","  #print(idx)\n","  val_frames.append(all_frames[idx])\n","  val_masks.append(all_masks[idx])\n","\n","for idx in test_idx:\n","  #print(idx)\n","  test_frames.append(all_frames[idx])\n","  test_masks.append(all_masks[idx])"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"-5PoEzTvOZA3","colab_type":"code","colab":{}},"source":["random.seed(230)\n","random.shuffle(all_frames)\n","random.seed(230)\n","random.shuffle(all_masks)\n","\n","\n","# Generate train, val, and test sets for frames\n","\n","train_split = int(0.7*len(all_frames))\n","val_split = int(0.9 * len(all_frames))\n","\n","train_frames = all_frames[:train_split]\n","val_frames = all_frames[train_split:val_split]\n","test_frames = all_frames[val_split:]\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ODYYuhQ5PGWj","colab_type":"code","colab":{}},"source":["def add_frames(dir_name, image):\n","  \n","  img = Image.open(FRAME_PATH + '/' +image)\n","  img.save(DATA_PATH+'/{}'.format(dir_name)+'/'+image)\n","  \n","  \n","  \n","def add_masks(dir_name, image):\n","  \n","  img = Image.open(MASK_PATH+ '/' +image)\n","  img.save(DATA_PATH+'/{}'.format(dir_name)+'/'+image)\n","\n","\n","  \n","  \n","frame_folders = [(train_frames, 'train_frames'), (val_frames, 'val_frames'), \n","                 (test_frames, 'test_frames')]\n","\n","mask_folders = [(train_masks, 'train_masks'), (val_masks, 'val_masks'), \n","                (test_masks, 'test_masks')]\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"pRzGV5SsVjQv","colab_type":"code","colab":{}},"source":["# Add frames\n","\n","for folder in frame_folders:\n","  \n","  array = folder[0]\n","  name = [folder[1]] * len(array)\n","  print(name)\n","  list(map(add_frames, name, array))\n","         \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"nVoLLhJ4VuKd","colab_type":"code","colab":{}},"source":["    \n","# Add masks\n","\n","for folder in mask_folders:\n","  \n","  array = folder[0]\n","  name = [folder[1]] * len(array)\n","  \n","  list(map(add_masks, name, array))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"pMga-N26xtyD","colab_type":"text"},"source":["**PART 2: CUSTOM GENERATOR AND NETWORK**"]},{"cell_type":"code","metadata":{"id":"omefKuARxtKc","colab_type":"code","colab":{}},"source":["import cv2\n","import os\n","import os\n","import random\n","import re\n","import numpy as np\n","import tensorflow as tf\n","from sklearn.utils import shuffle\n","tf.compat.v1.enable_eager_execution()\n","\n","def data_gen(img_folder, mask_folder, batch_size,imsize=128):\n","  c = 0\n","  #imsize=512;\n","  n = os.listdir(img_folder) #List of training images\n","  m = os.listdir(mask_folder) #List of Mask images\n","  n,m=shuffle(n,m)\n","  \n","  while (True):\n","    img = np.zeros((batch_size, imsize, imsize, 3)).astype('float')\n","    mask = np.zeros((batch_size, imsize, imsize, 3)).astype('int')\n","\n","    for i in range(c, c+batch_size): #initially from 0 to 16, c = 0. \n","\n","      train_img = cv2.imread(img_folder+'/'+n[i])/255.\n","      train_img =  cv2.resize(train_img, (imsize, imsize))# Read an image from folder and resize\n","      \n","      \n","\n","      \n","      train_mask = cv2.imread(mask_folder+'/'+m[i], cv2.IMREAD_GRAYSCALE)\n","      train_mask = cv2.resize(train_mask, (imsize, imsize))\n","      \n","\n","      #add augmentation\n","      toFlip=random.random()\n","\n","      if toFlip<=0.25:\n","        flipCode=0\n","      elif toFlip<=0.5 and toFlip>0.25:\n","        flipCode=-1\n","      elif toFlip>0.5 and toFlip<=75:\n","        flipCode=-1\n","      else:\n","        flipCode=2\n","      \n","      if flipCode!=2:\n","        train_img = cv2.flip(train_img, flipCode)\n","        train_mask = cv2.flip(train_mask, flipCode)\n","\n","\n","\n","      #ADD ONE-HOT ENCODING,\n","      train_mask=tf.one_hot(train_mask, 3)\n","      #add ims\n","      mask[i-c] = train_mask\n","      img[i-c] = train_img #add to array - img[0], img[1], and so on\n","    c+=batch_size\n","    if(c+batch_size>=len(os.listdir(img_folder))):\n","      c=0\n","      n,m=shuffle(n,m)\n","      #print \"randomizing again\"\n","    yield img, mask\n","\n","\n","\n","\n","train_frame_path = DATA_PATH+'/train_frames/'\n","train_mask_path = DATA_PATH+'/train_masks/'\n","\n","val_frame_path = DATA_PATH+'/val_frames/'\n","val_mask_path = DATA_PATH+'val_masks/'\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WjmgSb6Kpmbt","colab_type":"code","colab":{}},"source":["import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","\n","\n","def unet(pretrained_weights = None,input_size = (128,128,3)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","\n","    up6 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","\n","    up7 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","    merge7 = concatenate([conv3,up7], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(3, 1, activation = 'softmax',padding='same')(conv9)\n","\n","    model = Model(input = inputs, output = conv10)\n","\n","    #model.compile(optimizer = Adam(lr = 1e-4), loss = 'categorical_crossentropy', metrics = [tf.keras.metrics.MeanIoU(num_classes=3)])\n","    model.compile('Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","    #model.summary()\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"i6wKgDpUc2y8","colab_type":"text"},"source":["**PART 3: TRAINING**"]},{"cell_type":"code","metadata":{"id":"kyrGPBIyseuZ","colab_type":"code","colab":{}},"source":["#DEFINE LOSS\n","\n","from keras import backend as K\n","def weighted_categorical_crossentropy(weights):\n","    \"\"\"\n","    A weighted version of keras.objectives.categorical_crossentropy\n","    \n","    Variables:\n","        weights: numpy array of shape (C,) where C is the number of classes\n","    \n","    Usage:\n","        weights = np.array([0.5,2,10]) # Class one at 0.5, class 2 twice the normal weights, class 3 10x.\n","        loss = weighted_categorical_crossentropy(weights)\n","        model.compile(loss=loss,optimizer='adam')\n","    \"\"\"\n","    \n","    weights = K.variable(weights)\n","        \n","    def loss(y_true, y_pred):\n","        # scale predictions so that the class probas of each sample sum to 1\n","        y_pred /= K.sum(y_pred, axis=-1, keepdims=True)\n","        # clip to prevent NaN's and Inf's\n","        y_pred = K.clip(y_pred, K.epsilon(), 1 - K.epsilon())\n","        # calc\n","        loss = y_true * K.log(y_pred) * weights\n","        loss = -K.sum(loss, -1)\n","        return loss\n","    \n","    return loss"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DX9XZUric5_S","colab_type":"code","colab":{}},"source":["from keras.callbacks import ModelCheckpoint\n","from keras.callbacks import CSVLogger\n","from keras.callbacks import EarlyStopping\n","from keras.optimizers import Adam\n","from matplotlib import pyplot as plt\n","import os\n","import random\n","import re\n","\n","\n","\n","NO_OF_TRAINING_IMAGES = len(os.listdir(train_frame_path))\n","NO_OF_VAL_IMAGES = len(os.listdir(val_frame_path))\n","\n","NO_OF_EPOCHS = 500\n","BATCH_SIZE = 4\n","imsize=256\n","\n","weights_path = DATA_PATH+'/test'\n","#create network\n","m =unet(pretrained_weights = None,input_size = (imsize,imsize,3))\n","\n","#load weights\n","#m =unet(pretrained_weights = weights_path,input_size = (imsize,imsize,3))\n","\n","opt = Adam(lr=1E-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08)\n","\n","\n","myMetric=tf.keras.metrics.CategoricalAccuracy(name=\"categorical_accuracy\", dtype=None)\n","\n","#set weights for loss\n","weights = np.array([1,1,5]) \n","\n","loss = weighted_categorical_crossentropy(weights)\n","m.compile(loss=loss,\n","              optimizer=opt,\n","              metrics=[myMetric])\n","\n","#callbacks: monitor and save\n","checkpoint = ModelCheckpoint(weights_path, monitor=\"val_categorical_accuracy\", \n","                             verbose=1, save_best_only=True, mode='max')\n","\n","csv_logger = CSVLogger('./log.out', append=True, separator=';')\n","\n","earlystopping = EarlyStopping(monitor =\"val_categorical_accuracy\", verbose = 1, patience = 25, mode = 'max')\n","\n","\n","callbacks_list = [checkpoint, csv_logger, earlystopping]\n","\n","\n","train_gen = data_gen(train_frame_path,train_mask_path, batch_size = 4,imsize=imsize)\n","val_gen = data_gen(val_frame_path,val_mask_path, batch_size = 4,imsize=imsize)\n","\n","results = m.fit_generator(train_gen, epochs=NO_OF_EPOCHS, \n","                          steps_per_epoch = (NO_OF_TRAINING_IMAGES//BATCH_SIZE),\n","                          validation_data=val_gen, \n","                          validation_steps=(NO_OF_VAL_IMAGES//BATCH_SIZE), \n","                          callbacks=callbacks_list)\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ODklvxKOOrFH","colab_type":"text"},"source":["**PART 4: Evaluation**"]},{"cell_type":"code","metadata":{"id":"zK7PNBBX4-NM","colab_type":"code","colab":{}},"source":["\n","# list all data in history\n","history=results\n","print(history.history.keys())\n","# summarize history for accuracy\n","plt.plot(history.history['categorical_accuracy'])\n","plt.plot(history.history['val_categorical_accuracy'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()\n","# summarize history for loss\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'val'], loc='upper left')\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"xYcETX9CL51l","colab_type":"code","colab":{}},"source":["#define Intersection over Union Metric\n","\n","def getIOU(trumask,predmask,smooth=0):\n","  intersection=K.cast(trumask*predmask,dtype='float32')\n","  union=trumask+predmask\n","  union=K.cast(union>0,dtype='float32')\n","  \n","\n","  I=K.sum(intersection)\n","  U=K.sum(union)\n","  \n","  \n","  \n","  if smooth==1:\n","    IOUS=(I+1)/(U+1);\n","    return IOUS\n","  else:\n","    IOU=I/U\n","    return IOU\n","\n","  #print(IOUS)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"L2Ja-XGDKhPg","colab_type":"code","colab":{}},"source":["#Visualise results and measure IOU for channel 3\n","test_gen = data_gen(DATA_PATH+'/test_frames/',DATA_PATH+'/test_masks/', batch_size = 4,imsize=imsize)\n","from google.colab.patches import cv2_imshow\n","nucIOU=[]\n","area_real=[]\n","area_pred=[]\n","NO_OF_test_IMAGES = len(os.listdir(DATA_PATH+'/test_frames/'))\n","steps=(NO_OF_test_IMAGES//4)\n","hold_all_ims=np.zeros((NO_OF_test_IMAGES, imsize, imsize, 3)).astype('float')\n","hold_all_tru=np.zeros((NO_OF_test_IMAGES, imsize, imsize, 3)).astype('float')\n","hold_all_pred=np.zeros((NO_OF_test_IMAGES, imsize, imsize)).astype('float')\n","count=0;\n","for step in range(steps):\n","  x,y=next(test_gen)\n","  ans=m.predict(x,steps=(1))\n","\n","  for ind in range(4):\n","\n","    im=x[ind,:,:,:]\n","    im1=y[ind,:,:,:]\n","    im2=ans[ind,:,:,:]\n","    im2=np.argmax(im2,axis=2)\n","  \n","\n","    hold_all_ims[count]=im;\n","    hold_all_tru[count]=im1;\n","    hold_all_pred[count]=im2\n","\n","    cv2_imshow(im*125)\n","    cv2_imshow(im1*250)\n","    cv2_imshow(im2*125)\n","\n","    trumask=im1[:,:,2];\n","    predmask=im2>1;\n","\n","    nucIOU.append(getIOU(trumask,predmask,1))\n","    area_real.append(np.sum(trumask))\n","    area_pred.append(np.sum(predmask))\n","    count+=1\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"y8cd030it0Fy","colab_type":"code","colab":{}},"source":["#Shew worst/median/best result\n","def find_nearest(array, value):\n","    array = np.asarray(array)\n","    idx = (np.abs(array - value)).argmin()\n","    return array[idx]\n","\n","#calculate locations but set manually for consistency\n","min_loc=(nucIOU.index(min(nucIOU)))\n","print(min_loc)\n","#min_loc=21\n","max_loc=(nucIOU.index(max(nucIOU)))\n","print(max_loc)\n","#max_loc=45\n","med_loc=(nucIOU.index(find_nearest(nucIOU,np.median(nucIOU))))\n","print(med_loc)\n","#med_loc=7\n","\n","min_tru=hold_all_tru[min_loc]*250\n","max_tru=hold_all_tru[max_loc]*250\n","med_tru=hold_all_tru[med_loc]*250\n","\n","min_pred=hold_all_pred[min_loc]\n","nu_min_pred=np.zeros((imsize,imsize,3)).astype('float')\n","nu_min_pred[:,:,0]=min_pred\n","nu_min_pred[:,:,1]=min_pred\n","nu_min_pred[:,:,2]=min_pred\n","nu_min_pred*=125\n","max_pred=hold_all_pred[max_loc]\n","nu_max_pred=np.zeros((imsize,imsize,3)).astype('float')\n","nu_max_pred[:,:,0]=max_pred\n","nu_max_pred[:,:,1]=max_pred\n","nu_max_pred[:,:,2]=max_pred\n","nu_max_pred*=125\n","med_pred=hold_all_pred[med_loc]\n","nu_med_pred=np.zeros((imsize,imsize,3)).astype('float')\n","nu_med_pred[:,:,0]=med_pred\n","nu_med_pred[:,:,1]=med_pred\n","nu_med_pred[:,:,2]=med_pred\n","nu_med_pred*=125\n","\n","\n","min_im=hold_all_ims[min_loc]*125\n","max_im=hold_all_ims[max_loc]*125\n","med_im=hold_all_ims[med_loc]*125\n","\n","out_file=(cv2.vconcat([cv2.hconcat([min_im,min_tru,nu_min_pred]),cv2.hconcat([med_im,med_tru,nu_med_pred]),cv2.hconcat([max_im,max_tru,nu_max_pred])]))\n","cv2_imshow(out_file)\n","fname=(DATA_PATH+'/my_model_' + str(imsize) + '_WIOU_'+ str(np.median(nucIOU))+'.best-worst.png')\n","print(fname)\n","cv2.imwrite(out_file,fname)\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"OQjANdQMKfHb","colab_type":"code","colab":{}},"source":["##use this unet for imsize 512\n","#\n","\n","import numpy as np \n","import os\n","import skimage.io as io\n","import skimage.transform as trans\n","import numpy as np\n","from keras.models import *\n","from keras.layers import *\n","from keras.optimizers import *\n","from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n","from keras import backend as keras\n","\n","\n","def unet512(pretrained_weights = None,input_size = (512,512,3)):\n","    inputs = Input(input_size)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(inputs)\n","    conv1 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv1)\n","\n","    pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool1)\n","    conv2 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv2)\n","\n","    pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool2)\n","    conv3 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv3)\n","\n","    pool21 = MaxPooling2D(pool_size=(2, 2))(conv3)\n","    conv31 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool21)\n","    conv31 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv31)\n","\n","    pool3 = MaxPooling2D(pool_size=(2, 2))(conv31)\n","    conv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool3)\n","    conv4 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv4)\n","    drop4 = Dropout(0.5)(conv4)\n","    pool4 = MaxPooling2D(pool_size=(2, 2))(drop4)\n","\n","    conv5 = Conv2D(2048, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(pool4)\n","    conv5 = Conv2D(2048, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv5)\n","    drop5 = Dropout(0.5)(conv5)\n","    up6 = Conv2D(1024, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(drop5))\n","\n","    merge6 = concatenate([drop4,up6], axis = 3)\n","    conv6 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge6)\n","    conv6 = Conv2D(1024, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv6)\n","    up7 = Conv2D(512, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv6))\n","\n","    merge71 = concatenate([conv31,up7], axis = 3)\n","    conv71 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge71)\n","    conv71 = Conv2D(512, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv71)\n","    up81 = Conv2D(256, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv71))\n","\n","    merge7 = concatenate([conv3,up81], axis = 3)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge7)\n","    conv7 = Conv2D(256, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv7)\n","    up8 = Conv2D(128, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv7))\n","\n","    merge8 = concatenate([conv2,up8], axis = 3)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge8)\n","    conv8 = Conv2D(128, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv8)\n","    up9 = Conv2D(64, 2, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(UpSampling2D(size = (2,2))(conv8))\n","\n","    merge9 = concatenate([conv1,up9], axis = 3)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(merge9)\n","    conv9 = Conv2D(64, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv9 = Conv2D(3, 3, activation = 'relu', padding = 'same', kernel_initializer = 'he_normal')(conv9)\n","    conv10 = Conv2D(3, 1, activation = 'softmax',padding='same')(conv9)\n","\n","    model = Model(input = inputs, output = conv10)\n","\n","\n","    model.compile('Adam', loss='categorical_crossentropy', metrics=['categorical_accuracy'])\n","\n","\n","    if(pretrained_weights):\n","    \tmodel.load_weights(pretrained_weights)\n","\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"_wHIH9Q5EL5S","colab_type":"code","colab":{}},"source":["#custom IOU metric for monitoring, optional\n","def my_metric_fn(x, y):\n","    IOU=[]\n","    weights=[1.0,1.0,10.0]\n","    sumweights=tf.keras.backend.sum(weights)\n","    for ind in range(4):\n","\n","   \n","      im1=x[ind,:,:,:]\n","      im2=y[ind,:,:,:]\n","      im2=K.argmax(im2,axis=2)\n","      channelIOU=[]\n","      for channelin in range(3):\n","          trumask=im1[:,:,channelin];\n","          predmask=im2==channelin;\n","          unWiegtedIou=getIOU(tf.keras.backend.cast(trumask,dtype='float32'),tf.keras.backend.cast(predmask,dtype='float32'),1)\n","          channelIOU.append(unWiegtedIou/sumweights*weights[channelin])\n","      #print(channelIOU)\n","      IOU.append(tf.keras.backend.mean(tf.keras.backend.cast(channelIOU,dtype='float32')))\n","      \n","    return tf.keras.backend.mean(tf.keras.backend.cast(IOU,dtype='float32'))  # Note the `axis=-1`"],"execution_count":null,"outputs":[]}]}